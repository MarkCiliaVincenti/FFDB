- add Sql lite (use entity framework core)
- use entity framework core for postgresql provider

--------------

TeamsProcessor
	- Update Roster Mappings ****************
		[Stage ] Resolve New Rostered Players
			- find new by comparing rostered players versus whats currently in DB
				[DbContext - Player] Get All Players 
				[RosterCache]
		[Stage - GLOBAL] Fetch Save Players
			- foreach id, fetch from source and save to db
				[PlayerAddSource] Get 
				[DbContext - Player] Save Player
		*** OR, instead of the above 2 stages, we can just run the 
		        PlayerPRocessor.AddMissingRostered pipeline first!
		[Stage] Update
			[DbContext - Team] Update Roster Mappings

PlayerProcessor
	//- (NEW) Add Missing Rostered
	//	[Stage - GLOBAL] Resolve New Rostered Players
	//	[Stage - GLOBAL] Fetch Save Players
	- Update Currently Rostered - will ALSO add missing *******
		[Stage] Group by New and Existing
			[DbContext - Player] Get All
		[Stage - GLOBAL] Fetch Save Players (for new)
		[Stage - GLOBAL] Update Players
			foreach existing/update players:
			[PlayerUpdateSource] Get
			[DbContext - Player] Update Player (NEW)
	- Update All **********
		[Stage] Get All Existing
			[DbContext - Player] Get All
				- set to Update Ids
		[Stage - GLOBAL] Update Player 
			
StatsPRocessor
	REMOVE these 2 existing ones:
		- Remove All
		- Remove For Week
		all other methods will intelligently determine what to add, even if a previous
		run was incomplete.
		Things that are updated:
			- Player WeekStats
			- Team WeekStats
			- Game Matchups
	- Add Missing
		[Stage] Get Missing Weeks
			- Get All Available
			- Get Missing by comparing all to update log
				[DbContext - Logs] Get All
		[Stage] - Update/Add Stats
			- for each missing week, run the "AddForWeek" pipeline
				- need to scope certain things like caches so they "reset" per week run
	- Add For Week
		[Stage] Check Already Updated
			[DbContext - Logs] Has Updated Week
		[Stage] Add Stats
			PlayerWeekStats
				[Source - PlayerWeekStats] Get For Week
				Get PlayerIds from week stats and FETCH/SAVE new players
				[DbContext - Stats] - Add Player WeekStats
			TeamWeekStats
				[Source - TeamWeekStats] Get For Week
				[DbContext - Stats] - Add Team WeekStats
			WeekMatchups
				[Source - WeekMatchups] - Get For Week
				[DbContext - Teams] - Add Matchups for Week
		[Stage] Add Log
			[DbContext - Log] Add For Week
		
				

new DBCONTEXT api:
[Base]
	- Has Been Initialized
	- Initialize
[Player]
	- Get All
	- Save
	- Update
[Team]
	- Add All
	- Update Roster Mappings
	- Add Matchups for Week
[Logs]
	- Get Updated Weeks
	- Has Updated Week
	- Add For Week
[Stats] NEW
	- Add Player Week Stats
	- Add Team Week Stats



-------------------------

- convert teamdatastore to a class that reads from json file?
- core data sources should have option to save original source files? (in temp/source?)
-logging


-------

- Use Lazy<T> or AsyncLazy<T> for currenty custom async stuff?
- memory caching (scoped per week)
	- note: if a pipeline updates more than a week (eg update-all, update-missing),
	        ensure that caches are reset (while thinking about certain cached items
			that may need to STICK around)

- there should be an option (rollback/reverse) such that when running a stats update for a week, IF it fails
  it will undo everything done up to that point (should be defaulted to true? think about this)
  - to handle the case where things are NOT undone, every update should run smartly. meaning, if an entry or something
    has previously been completed partially, it will not try to reupdate/add etc

NEW ARCHITECTURE plans (using source versioning)
all the StaticCoreDataSources should be versioned
they will fetch and returned a VersionedModel, that will eventually
be mapped to the core entities. This creates a nice boundary such that
if a source needs to be updated or stops working, we only need to worry
about creating a new StaticCoreDataSource with an updated version, everything
else should remain working.
- to detect which sources to use, we'll later use reflection to find them
	- default to the latest version? if that fails while updating, try falling
	  back to older ones in backwards order or something

----------------------------------------------

remove StaticDataDirectoryPath.WeekGames
  - it now uses the new WeekGamesMatchups

add static helpers to DataPath to easily get file paths based
on params like week, etc

update access modifiers to as restrictive as needed (mainly public -> internal)
-unit & functional tests for everything
- documentation
- get image/diagram of db schemas (both mongo and postgres) for alpha release discussion

- move fetching from sources into SOURCE classes
  - abstracts away, so we can check individual source health and possibly in the future add more than 1 for redundancy

---------------
need a SaveToDisk switch (or the opposite)

- Caching static data on init
-- loading all new week stats into memory takes: 8,072,856 = ~8MB (not too bad, should def cache all this)
- weekstats = 21,307,216 (ont too bad)

------------------------------------------

RunInfoBuilder needs to be updated to allow for 
global options that can be accessed in any command.
- for now, making it work by adding the same --config option
to every option in the command tree
- same with the --SkipRosterFetch option!

cleanup baseservicecollection adding of services

go through and update access modifiers (internal, etc)

add readme docs and c# comments

-------------------------------

get TARGETS, 
NFL.com has a stats/overview page for each game
- find some way to get to that, and extract targets information


-- ALSO, team pages on NFL has stats like totla rushing, passing, sacks, etc
which should be added

- rethink the model of how static json files are saved.
currently saving the entire thing, but could lower the total disk space usage
by A LOT by only extracing what we need into a more useable model.
- this would allow updating stuff all in memory easier too.
     - we can use the current logic of parsing the ENTIRE file, such that
	   we make the json requests on the fly as needed, and apply the same logic
	   to map those into a more useable model.
	 - OR, if you want to save, it will first map to the SAME useable model
	   first before saving.
	 - from there, any logic shold be the same, whether you're saving files to disk
	   or not